{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "variational classifier is also called quantum parameterized circuits or quantum neural networks.\n",
        "The algorithm contains few ingredients:\n",
        "1. A circuit ansatz ( the architecture of the circuit)\n",
        "2. cost function \n",
        "3. Training procedure ( gradient descent/ update circuit parameter) \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "y-qYjpKNxSUF"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TZxZEw8HPdMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pennylane"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DA-Ap-pVd_et",
        "outputId": "9177bd7f-5bd6-493e-bce9-9e767445017c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pennylane in /usr/local/lib/python3.7/dist-packages (0.24.0)\n",
            "Requirement already satisfied: autoray>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from pennylane) (0.3.2)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.7/dist-packages (from pennylane) (1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pennylane) (1.21.6)\n",
            "Requirement already satisfied: pennylane-lightning>=0.24 in /usr/local/lib/python3.7/dist-packages (from pennylane) (0.24.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pennylane) (1.4.1)\n",
            "Requirement already satisfied: retworkx in /usr/local/lib/python3.7/dist-packages (from pennylane) (0.11.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from pennylane) (0.10.2)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pennylane) (1.4.4)\n",
            "Requirement already satisfied: semantic-version==2.6 in /usr/local/lib/python3.7/dist-packages (from pennylane) (2.6.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from pennylane) (2.6.3)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.7/dist-packages (from pennylane) (4.2.4)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.7/dist-packages (from pennylane-lightning>=0.24->pennylane) (1.10.2.3)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from autograd->pennylane) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-HWH7Fxdsjq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pennylane import numpy as np\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import pennylane as qml\n",
        "from pennylane.templates.embeddings import AngleEmbedding, AmplitudeEmbedding\n",
        "from pennylane.optimize import AdamOptimizer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "import time\n",
        "start = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/ClaMP_Integrated-5184.csv', sep=',')"
      ],
      "metadata": {
        "id": "A958aqj9fMj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['packer_type'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "s-7FdTd7fb5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read out CSV and sets/samples creation\n",
        "\n",
        "df = df.astype(float)\n",
        "train,test = train_test_split(df, test_size=0.30, random_state=2)\n",
        "train_set = train\n",
        "test_set = test\n",
        "train_set = train_set.sample(160)\n",
        "test_set = test_set.sample(40)\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "vQ8STnHgd7t2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyE-vDXxd717",
        "outputId": "fcd55323-ed8d-4846-fccb-8b7b3034c981"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.info of       e_cblp  e_cp  e_cparhdr  e_maxalloc   e_sp  e_lfanew  NumberOfSections  \\\n",
              "0      144.0   3.0        4.0     65535.0  184.0     256.0               4.0   \n",
              "1      144.0   3.0        4.0     65535.0  184.0     184.0               4.0   \n",
              "2      144.0   3.0        4.0     65535.0  184.0     272.0               5.0   \n",
              "3      144.0   3.0        4.0     65535.0  184.0     184.0               1.0   \n",
              "4      144.0   3.0        4.0     65535.0  184.0     224.0               5.0   \n",
              "...      ...   ...        ...         ...    ...       ...               ...   \n",
              "5205   144.0   3.0        4.0     65535.0  184.0     216.0               5.0   \n",
              "5206    80.0   2.0        4.0     65535.0  184.0     256.0               7.0   \n",
              "5207   144.0   3.0        4.0     65535.0  184.0     216.0               5.0   \n",
              "5208   144.0   3.0        4.0     65535.0  184.0     248.0               5.0   \n",
              "5209   144.0   3.0        4.0     65535.0  184.0     240.0               4.0   \n",
              "\n",
              "      CreationYear  FH_char0  FH_char1  ...  LoaderFlags  sus_sections  \\\n",
              "0              1.0       0.0       1.0  ...          1.0           1.0   \n",
              "1              1.0       0.0       1.0  ...          1.0           1.0   \n",
              "2              1.0       0.0       1.0  ...          1.0           1.0   \n",
              "3              1.0       0.0       1.0  ...          1.0           0.0   \n",
              "4              1.0       0.0       1.0  ...          1.0           1.0   \n",
              "...            ...       ...       ...  ...          ...           ...   \n",
              "5205           1.0       1.0       1.0  ...          1.0           0.0   \n",
              "5206           1.0       0.0       1.0  ...          1.0           4.0   \n",
              "5207           1.0       0.0       1.0  ...          1.0           2.0   \n",
              "5208           1.0       1.0       1.0  ...          1.0           1.0   \n",
              "5209           1.0       1.0       1.0  ...          1.0           0.0   \n",
              "\n",
              "      non_sus_sections  packer    E_text    E_data   filesize    E_file  \\\n",
              "0                  3.0     0.0  6.603616  5.443362  1181520.0  6.627552   \n",
              "1                  3.0     0.0  5.205926  2.123522     7680.0  5.318221   \n",
              "2                  4.0     0.0  6.238000  3.380859    57872.0  6.507758   \n",
              "3                  1.0     0.0  0.000000  0.000000    95616.0  4.575092   \n",
              "4                  4.0     0.0  6.355626  0.702621    48128.0  5.545531   \n",
              "...                ...     ...       ...       ...        ...       ...   \n",
              "5205               5.0     0.0  6.174602  3.155928   365568.0  7.546568   \n",
              "5206               3.0     0.0  0.000000  0.000000    98816.0  6.947195   \n",
              "5207               3.0     0.0  6.503422  3.790871   227328.0  7.823114   \n",
              "5208               4.0     0.0  6.115208  7.919091   271616.0  7.886012   \n",
              "5209               4.0     0.0  7.524554  7.779965   130560.0  7.345463   \n",
              "\n",
              "      fileinfo  class  \n",
              "0          1.0    0.0  \n",
              "1          0.0    0.0  \n",
              "2          1.0    0.0  \n",
              "3          1.0    0.0  \n",
              "4          1.0    0.0  \n",
              "...        ...    ...  \n",
              "5205       0.0    1.0  \n",
              "5206       0.0    1.0  \n",
              "5207       0.0    1.0  \n",
              "5208       0.0    1.0  \n",
              "5209       1.0    1.0  \n",
              "\n",
              "[5210 rows x 69 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "OdqpIrRgd74x",
        "outputId": "afd54080-12b6-4610-851e-2417b63a82b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             e_cblp          e_cp     e_cparhdr    e_maxalloc          e_sp  \\\n",
              "count   5210.000000   5210.000000   5210.000000   5210.000000   5210.000000   \n",
              "mean     152.658733     10.633589      8.903263  65137.618234    202.530902   \n",
              "std      616.499070    392.745064    251.685103   5005.606042    968.625098   \n",
              "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "25%      144.000000      3.000000      4.000000  65535.000000    184.000000   \n",
              "50%      144.000000      3.000000      4.000000  65535.000000    184.000000   \n",
              "75%      144.000000      3.000000      4.000000  65535.000000    184.000000   \n",
              "max    37008.000000  20050.000000  12851.000000  65535.000000  65534.000000   \n",
              "\n",
              "          e_lfanew  NumberOfSections  CreationYear     FH_char0  FH_char1  \\\n",
              "count  5210.000000       5210.000000   5210.000000  5210.000000    5210.0   \n",
              "mean    222.833013          4.662956      0.990403     0.362764       1.0   \n",
              "std      48.591497          1.922882      0.097502     0.480844       0.0   \n",
              "min      12.000000          1.000000      0.000000     0.000000       1.0   \n",
              "25%     208.000000          4.000000      1.000000     0.000000       1.0   \n",
              "50%     232.000000          5.000000      1.000000     0.000000       1.0   \n",
              "75%     248.000000          5.000000      1.000000     1.000000       1.0   \n",
              "max     648.000000         34.000000      1.000000     1.000000       1.0   \n",
              "\n",
              "       ...  LoaderFlags  sus_sections  non_sus_sections       packer  \\\n",
              "count  ...  5210.000000   5210.000000       5210.000000  5210.000000   \n",
              "mean   ...     0.999040      1.360845          3.302111     0.156430   \n",
              "std    ...     0.030967      1.623972          1.146956     0.363297   \n",
              "min    ...     0.000000      0.000000          0.000000     0.000000   \n",
              "25%    ...     1.000000      1.000000          3.000000     0.000000   \n",
              "50%    ...     1.000000      1.000000          4.000000     0.000000   \n",
              "75%    ...     1.000000      2.000000          4.000000     0.000000   \n",
              "max    ...     1.000000     31.000000          8.000000     1.000000   \n",
              "\n",
              "            E_text       E_data      filesize       E_file     fileinfo  \\\n",
              "count  5210.000000  5210.000000  5.210000e+03  5210.000000  5210.000000   \n",
              "mean      4.939586     2.523549  7.875718e+05     6.364756     0.544146   \n",
              "std       2.521787     2.685909  5.293440e+06     1.119881     0.498095   \n",
              "min       0.000000     0.000000  1.536000e+03     0.939626     0.000000   \n",
              "25%       3.886006     0.000000  6.144000e+04     5.695785     0.000000   \n",
              "50%       6.148211     1.555973  1.218560e+05     6.390618     1.000000   \n",
              "75%       6.507072     4.685836  3.055480e+05     7.314531     1.000000   \n",
              "max       7.999859     7.999620  1.657081e+08     7.999997     1.000000   \n",
              "\n",
              "             class  \n",
              "count  5210.000000  \n",
              "mean      0.522457  \n",
              "std       0.499543  \n",
              "min       0.000000  \n",
              "25%       0.000000  \n",
              "50%       1.000000  \n",
              "75%       1.000000  \n",
              "max       1.000000  \n",
              "\n",
              "[8 rows x 69 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-97d9b386-d9a2-46de-816a-28aa8fb1875f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>e_cblp</th>\n",
              "      <th>e_cp</th>\n",
              "      <th>e_cparhdr</th>\n",
              "      <th>e_maxalloc</th>\n",
              "      <th>e_sp</th>\n",
              "      <th>e_lfanew</th>\n",
              "      <th>NumberOfSections</th>\n",
              "      <th>CreationYear</th>\n",
              "      <th>FH_char0</th>\n",
              "      <th>FH_char1</th>\n",
              "      <th>...</th>\n",
              "      <th>LoaderFlags</th>\n",
              "      <th>sus_sections</th>\n",
              "      <th>non_sus_sections</th>\n",
              "      <th>packer</th>\n",
              "      <th>E_text</th>\n",
              "      <th>E_data</th>\n",
              "      <th>filesize</th>\n",
              "      <th>E_file</th>\n",
              "      <th>fileinfo</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5210.000000</td>\n",
              "      <td>5210.000000</td>\n",
              "      <td>5210.000000</td>\n",
              "      <td>5210.000000</td>\n",
              "      <td>5210.000000</td>\n",
              "      <td>5210.000000</td>\n",
              "      <td>5210.000000</td>\n",
              "      <td>5210.000000</td>\n",
              "      <td>5210.000000</td>\n",
              "      <td>5210.0</td>\n",
              "      <td>...</td>\n",
              "      <td>5210.000000</td>\n",
              "      <td>5210.000000</td>\n",
              "      <td>5210.000000</td>\n",
              "      <td>5210.000000</td>\n",
              "      <td>5210.000000</td>\n",
              "      <td>5210.000000</td>\n",
              "      <td>5.210000e+03</td>\n",
              "      <td>5210.000000</td>\n",
              "      <td>5210.000000</td>\n",
              "      <td>5210.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>152.658733</td>\n",
              "      <td>10.633589</td>\n",
              "      <td>8.903263</td>\n",
              "      <td>65137.618234</td>\n",
              "      <td>202.530902</td>\n",
              "      <td>222.833013</td>\n",
              "      <td>4.662956</td>\n",
              "      <td>0.990403</td>\n",
              "      <td>0.362764</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.999040</td>\n",
              "      <td>1.360845</td>\n",
              "      <td>3.302111</td>\n",
              "      <td>0.156430</td>\n",
              "      <td>4.939586</td>\n",
              "      <td>2.523549</td>\n",
              "      <td>7.875718e+05</td>\n",
              "      <td>6.364756</td>\n",
              "      <td>0.544146</td>\n",
              "      <td>0.522457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>616.499070</td>\n",
              "      <td>392.745064</td>\n",
              "      <td>251.685103</td>\n",
              "      <td>5005.606042</td>\n",
              "      <td>968.625098</td>\n",
              "      <td>48.591497</td>\n",
              "      <td>1.922882</td>\n",
              "      <td>0.097502</td>\n",
              "      <td>0.480844</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.030967</td>\n",
              "      <td>1.623972</td>\n",
              "      <td>1.146956</td>\n",
              "      <td>0.363297</td>\n",
              "      <td>2.521787</td>\n",
              "      <td>2.685909</td>\n",
              "      <td>5.293440e+06</td>\n",
              "      <td>1.119881</td>\n",
              "      <td>0.498095</td>\n",
              "      <td>0.499543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.536000e+03</td>\n",
              "      <td>0.939626</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>144.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>65535.000000</td>\n",
              "      <td>184.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.886006</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.144000e+04</td>\n",
              "      <td>5.695785</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>144.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>65535.000000</td>\n",
              "      <td>184.000000</td>\n",
              "      <td>232.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.148211</td>\n",
              "      <td>1.555973</td>\n",
              "      <td>1.218560e+05</td>\n",
              "      <td>6.390618</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>144.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>65535.000000</td>\n",
              "      <td>184.000000</td>\n",
              "      <td>248.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.507072</td>\n",
              "      <td>4.685836</td>\n",
              "      <td>3.055480e+05</td>\n",
              "      <td>7.314531</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>37008.000000</td>\n",
              "      <td>20050.000000</td>\n",
              "      <td>12851.000000</td>\n",
              "      <td>65535.000000</td>\n",
              "      <td>65534.000000</td>\n",
              "      <td>648.000000</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>7.999859</td>\n",
              "      <td>7.999620</td>\n",
              "      <td>1.657081e+08</td>\n",
              "      <td>7.999997</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 69 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-97d9b386-d9a2-46de-816a-28aa8fb1875f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-97d9b386-d9a2-46de-816a-28aa8fb1875f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-97d9b386-d9a2-46de-816a-28aa8fb1875f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separation of labels\n",
        "\n",
        "x_train = train_set\n",
        "y_train = train_set[['class']]\n",
        "\n",
        "x_test = test_set\n",
        "y_test = test_set[['class']]"
      ],
      "metadata": {
        "id": "I6NZgivdd77o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce dimensions using PCA to fit the dimensions with the qubits\n",
        "\n",
        "n_dim = 2\n",
        "pca = PCA(n_components=n_dim)\n",
        "pca.fit(x_train)\n",
        "\n",
        "x_train = pca.transform(x_train)\n",
        "\n",
        "pca.fit(x_test)\n",
        "x_test = pca.transform(x_test)"
      ],
      "metadata": {
        "id": "b4fQM1TPd7-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize\n",
        "\n",
        "std_scale = StandardScaler().fit(x_train)\n",
        "data = std_scale.transform(x_train)\n",
        "\n",
        "std_scale = StandardScaler().fit(x_test)\n",
        "x_test = std_scale.transform(x_test)"
      ],
      "metadata": {
        "id": "Z_AVa-n1d-cb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Review the balance of the target variable in train\n",
        "\n",
        "y_train.value_counts(normalize=True)*100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcnn8Qr0gCMp",
        "outputId": "0f15baff-f2ce-487a-cb82-841bd3e89a43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "class\n",
              "0.0      51.875\n",
              "1.0      48.125\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Review the balance of the target variable in test\n",
        "\n",
        "y_test.value_counts(normalize=True)*100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6x1pbgRgG21",
        "outputId": "1e8e94f7-e231-446d-b00a-7ff41baf64eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "class\n",
              "1.0      55.0\n",
              "0.0      45.0\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Angle Encoding\n",
        "\n",
        "num_qubits = n_dim\n",
        "\n",
        "dev = qml.device('default.qubit', wires = num_qubits)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def circuit(parameters, data):\n",
        "    for i in range(num_qubits):\n",
        "        qml.Hadamard(wires = i)\n",
        "    \n",
        "    AngleEmbedding(features = data, wires = range(num_qubits), rotation = 'Y')\n",
        "    \n",
        "    qml.StronglyEntanglingLayers(weights = parameters, wires = range(num_qubits))\n",
        "    \n",
        "    return qml.expval(qml.PauliZ(0))"
      ],
      "metadata": {
        "id": "fkEj9K_tgKod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_layers = 5\n",
        "weights_init = 0.01 * np.random.randn(num_layers, num_qubits, 3, requires_grad=True)\n",
        "bias_init = np.array(0.0, requires_grad=True)\n",
        "\n",
        "print(weights_init, bias_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6n3y_5PgP1A",
        "outputId": "469418f5-bcdf-4493-a785-08aaa79859b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[-0.00601707  0.01852278 -0.00013497]\n",
            "  [-0.01057711  0.00822545 -0.01220844]]\n",
            "\n",
            " [[ 0.00208864 -0.0195967  -0.01328186]\n",
            "  [ 0.00196861  0.00738467  0.00171368]]\n",
            "\n",
            " [[-0.00115648 -0.00301104 -0.01478522]\n",
            "  [-0.00719844 -0.00460639  0.01057122]]\n",
            "\n",
            " [[ 0.00343618 -0.0176304   0.00324084]\n",
            "  [-0.00385082 -0.00676922  0.00611676]]\n",
            "\n",
            " [[ 0.01031     0.0093128  -0.00839218]\n",
            "  [-0.00309212  0.00331263  0.00975545]]] 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "circuit(weights_init, data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KworMWb4gTk-",
        "outputId": "b9941096-9105-47bf-f6b6-5a5ba190116d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.01214696, requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def variational_classifier(weights, bias, x):\n",
        "    return circuit(weights, x) + bias\n"
      ],
      "metadata": {
        "id": "1Mk_AxCMgXiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def square_loss(labels, predictions):\n",
        "    loss = 0\n",
        "    for l, p in zip(labels, predictions):\n",
        "        loss = loss + (l - p) ** 2\n",
        "\n",
        "    loss = loss / len(labels)\n",
        "    return loss\n"
      ],
      "metadata": {
        "id": "Fmlv3FGSgXk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(labels, predictions):\n",
        "\n",
        "    loss = 0\n",
        "    for l, p in zip(labels, predictions):\n",
        "        if abs(l - p) < 1e-5:\n",
        "            loss = loss + 1\n",
        "    loss = loss / len(labels)\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "id": "xtGK287RgXoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cost(weights, bias, X, Y):\n",
        "    predictions = [variational_classifier(weights, bias, x) for x in X]\n",
        "    return square_loss(Y, predictions)"
      ],
      "metadata": {
        "id": "YDhBcjD-gfOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = np.array(y_train.values[:,0] * 2 - np.ones(len(y_train.values[:,0])), requires_grad = False)  # shift label from {0, 1} to {-1, 1}\n",
        "X = np.array(data, requires_grad=False)\n",
        "\n",
        "for i in range(5):\n",
        "    print(\"X = {}, Y = {: d}\".format(list(X[i]), int(Y[i])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbUoTe13gfRO",
        "outputId": "af0a95ba-48b2-4411-e566-5f23eaa12075"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X = [tensor(-0.07954832, requires_grad=False), tensor(-0.25290842, requires_grad=False)], Y = -1\n",
            "X = [tensor(-0.08034127, requires_grad=False), tensor(1.94352618, requires_grad=False)], Y =  1\n",
            "X = [tensor(-0.08126536, requires_grad=False), tensor(4.36642967, requires_grad=False)], Y =  1\n",
            "X = [tensor(-0.07521629, requires_grad=False), tensor(-0.52175067, requires_grad=False)], Y = -1\n",
            "X = [tensor(-0.07755101, requires_grad=False), tensor(-0.25030712, requires_grad=False)], Y =  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt = AdamOptimizer(stepsize=0.1, beta1=0.9, beta2=0.99, eps=1e-08)\n",
        "batch_size = 10"
      ],
      "metadata": {
        "id": "roo7kxPKgfUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = weights_init\n",
        "bias = bias_init\n",
        "\n",
        "wbest = 0\n",
        "bbest = 0\n",
        "abest = 0\n",
        "\n",
        "for it in range(100):\n",
        "\n",
        "    # weights update by one optimizer step\n",
        "\n",
        "    batch_index = np.random.randint(0, len(X), (batch_size,))\n",
        "    X_batch = X[batch_index]\n",
        "    Y_batch = Y[batch_index]\n",
        "    weights, bias, _, _ = opt.step(cost, weights, bias, X_batch, Y_batch)\n",
        "\n",
        "    # Compute the accuracy\n",
        "    predictions = [np.sign(variational_classifier(weights, bias, x)) for x in X]\n",
        "    \n",
        "    if accuracy(Y, predictions) > abest:\n",
        "        wbest = weights\n",
        "        bbest = bias\n",
        "        abest = accuracy(Y, predictions)\n",
        "        print('New best')\n",
        "\n",
        "    acc = accuracy(Y, predictions)\n",
        "\n",
        "    print(\n",
        "        \"Iter: {:5d} | Cost: {:0.7f} | Accuracy: {:0.7f} \".format(\n",
        "            it + 1, cost(weights, bias, X, Y), acc\n",
        "        )\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnSR-rNegnot",
        "outputId": "e51b2703-0b05-43bc-aee5-9c35036ad238"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New best\n",
            "Iter:     1 | Cost: 1.0763623 | Accuracy: 0.5187500 \n",
            "Iter:     2 | Cost: 1.0278761 | Accuracy: 0.4250000 \n",
            "Iter:     3 | Cost: 1.1741594 | Accuracy: 0.4562500 \n",
            "Iter:     4 | Cost: 1.1544134 | Accuracy: 0.4812500 \n",
            "Iter:     5 | Cost: 1.0509583 | Accuracy: 0.4562500 \n",
            "New best\n",
            "Iter:     6 | Cost: 0.9984045 | Accuracy: 0.5375000 \n",
            "New best\n",
            "Iter:     7 | Cost: 1.0004401 | Accuracy: 0.5562500 \n",
            "Iter:     8 | Cost: 1.0052084 | Accuracy: 0.5562500 \n",
            "Iter:     9 | Cost: 1.0061520 | Accuracy: 0.5562500 \n",
            "Iter:    10 | Cost: 1.0178625 | Accuracy: 0.3375000 \n",
            "Iter:    11 | Cost: 1.0821308 | Accuracy: 0.4562500 \n",
            "Iter:    12 | Cost: 1.1361917 | Accuracy: 0.4562500 \n",
            "Iter:    13 | Cost: 1.1804824 | Accuracy: 0.4562500 \n",
            "Iter:    14 | Cost: 1.0680494 | Accuracy: 0.4312500 \n",
            "Iter:    15 | Cost: 1.0296217 | Accuracy: 0.5187500 \n",
            "Iter:    16 | Cost: 1.0944602 | Accuracy: 0.5187500 \n",
            "Iter:    17 | Cost: 1.1487291 | Accuracy: 0.5187500 \n",
            "Iter:    18 | Cost: 1.1143382 | Accuracy: 0.5187500 \n",
            "Iter:    19 | Cost: 1.0765355 | Accuracy: 0.5187500 \n",
            "Iter:    20 | Cost: 1.0131749 | Accuracy: 0.5250000 \n",
            "Iter:    21 | Cost: 1.0758451 | Accuracy: 0.4250000 \n",
            "Iter:    22 | Cost: 1.1558622 | Accuracy: 0.4375000 \n",
            "Iter:    23 | Cost: 1.1793298 | Accuracy: 0.4625000 \n",
            "Iter:    24 | Cost: 1.1860076 | Accuracy: 0.4812500 \n",
            "Iter:    25 | Cost: 1.1138293 | Accuracy: 0.4812500 \n",
            "Iter:    26 | Cost: 1.0679890 | Accuracy: 0.4812500 \n",
            "Iter:    27 | Cost: 1.0292250 | Accuracy: 0.4812500 \n",
            "Iter:    28 | Cost: 1.0056246 | Accuracy: 0.4812500 \n",
            "New best\n",
            "Iter:    29 | Cost: 0.9951828 | Accuracy: 0.5875000 \n",
            "Iter:    30 | Cost: 0.9928957 | Accuracy: 0.5500000 \n",
            "Iter:    31 | Cost: 0.9940221 | Accuracy: 0.5250000 \n",
            "Iter:    32 | Cost: 0.9976010 | Accuracy: 0.5187500 \n",
            "Iter:    33 | Cost: 1.0019632 | Accuracy: 0.5187500 \n",
            "Iter:    34 | Cost: 1.0064764 | Accuracy: 0.5250000 \n",
            "Iter:    35 | Cost: 1.0167746 | Accuracy: 0.4312500 \n",
            "New best\n",
            "Iter:    36 | Cost: 1.0152610 | Accuracy: 0.6062500 \n",
            "Iter:    37 | Cost: 1.0175774 | Accuracy: 0.4312500 \n",
            "Iter:    38 | Cost: 1.0128303 | Accuracy: 0.5250000 \n",
            "Iter:    39 | Cost: 1.0121156 | Accuracy: 0.5312500 \n",
            "New best\n",
            "Iter:    40 | Cost: 1.0116242 | Accuracy: 0.6750000 \n",
            "Iter:    41 | Cost: 1.0145783 | Accuracy: 0.4375000 \n",
            "Iter:    42 | Cost: 1.0274819 | Accuracy: 0.4250000 \n",
            "Iter:    43 | Cost: 1.0341104 | Accuracy: 0.4250000 \n",
            "Iter:    44 | Cost: 1.0257544 | Accuracy: 0.4312500 \n",
            "Iter:    45 | Cost: 1.0171231 | Accuracy: 0.4312500 \n",
            "Iter:    46 | Cost: 1.0085166 | Accuracy: 0.4312500 \n",
            "Iter:    47 | Cost: 0.9951237 | Accuracy: 0.5437500 \n",
            "Iter:    48 | Cost: 0.9905569 | Accuracy: 0.5437500 \n",
            "Iter:    49 | Cost: 0.9883516 | Accuracy: 0.5437500 \n",
            "Iter:    50 | Cost: 0.9857572 | Accuracy: 0.5437500 \n",
            "Iter:    51 | Cost: 0.9834601 | Accuracy: 0.5625000 \n",
            "Iter:    52 | Cost: 0.9894757 | Accuracy: 0.5687500 \n",
            "Iter:    53 | Cost: 0.9908151 | Accuracy: 0.5687500 \n",
            "Iter:    54 | Cost: 0.9907295 | Accuracy: 0.5687500 \n",
            "Iter:    55 | Cost: 0.9727789 | Accuracy: 0.5812500 \n",
            "Iter:    56 | Cost: 0.9731466 | Accuracy: 0.5812500 \n",
            "Iter:    57 | Cost: 0.9992038 | Accuracy: 0.4812500 \n",
            "Iter:    58 | Cost: 1.0197919 | Accuracy: 0.4812500 \n",
            "Iter:    59 | Cost: 1.0335747 | Accuracy: 0.4812500 \n",
            "Iter:    60 | Cost: 1.0172384 | Accuracy: 0.4812500 \n",
            "Iter:    61 | Cost: 1.0062293 | Accuracy: 0.4812500 \n",
            "Iter:    62 | Cost: 1.0090608 | Accuracy: 0.4812500 \n",
            "Iter:    63 | Cost: 1.0066169 | Accuracy: 0.4812500 \n",
            "Iter:    64 | Cost: 0.9923962 | Accuracy: 0.4812500 \n",
            "Iter:    65 | Cost: 0.9926281 | Accuracy: 0.4812500 \n",
            "Iter:    66 | Cost: 0.9724819 | Accuracy: 0.3812500 \n",
            "Iter:    67 | Cost: 0.9638043 | Accuracy: 0.5812500 \n",
            "Iter:    68 | Cost: 0.9623208 | Accuracy: 0.5812500 \n",
            "Iter:    69 | Cost: 0.9630746 | Accuracy: 0.5812500 \n",
            "Iter:    70 | Cost: 0.9839175 | Accuracy: 0.5812500 \n",
            "Iter:    71 | Cost: 0.9731498 | Accuracy: 0.5812500 \n",
            "Iter:    72 | Cost: 0.9605036 | Accuracy: 0.5812500 \n",
            "Iter:    73 | Cost: 0.9579746 | Accuracy: 0.5812500 \n",
            "Iter:    74 | Cost: 0.9590454 | Accuracy: 0.5812500 \n",
            "Iter:    75 | Cost: 0.9605568 | Accuracy: 0.5812500 \n",
            "Iter:    76 | Cost: 0.9526488 | Accuracy: 0.5812500 \n",
            "Iter:    77 | Cost: 0.9496475 | Accuracy: 0.5812500 \n",
            "Iter:    78 | Cost: 0.9502506 | Accuracy: 0.5875000 \n",
            "Iter:    79 | Cost: 0.9487784 | Accuracy: 0.5875000 \n",
            "Iter:    80 | Cost: 0.9467350 | Accuracy: 0.5812500 \n",
            "Iter:    81 | Cost: 0.9491616 | Accuracy: 0.5812500 \n",
            "Iter:    82 | Cost: 0.9473180 | Accuracy: 0.5812500 \n",
            "Iter:    83 | Cost: 0.9461535 | Accuracy: 0.5750000 \n",
            "Iter:    84 | Cost: 0.9467031 | Accuracy: 0.5750000 \n",
            "Iter:    85 | Cost: 0.9507319 | Accuracy: 0.5750000 \n",
            "Iter:    86 | Cost: 0.9741170 | Accuracy: 0.4812500 \n",
            "Iter:    87 | Cost: 0.9827786 | Accuracy: 0.4750000 \n",
            "Iter:    88 | Cost: 0.9606105 | Accuracy: 0.6687500 \n",
            "Iter:    89 | Cost: 0.9509224 | Accuracy: 0.5750000 \n",
            "Iter:    90 | Cost: 0.9467880 | Accuracy: 0.5750000 \n",
            "Iter:    91 | Cost: 0.9523874 | Accuracy: 0.5687500 \n",
            "Iter:    92 | Cost: 0.9855980 | Accuracy: 0.5687500 \n",
            "Iter:    93 | Cost: 1.0296581 | Accuracy: 0.5687500 \n",
            "Iter:    94 | Cost: 1.0411775 | Accuracy: 0.5812500 \n",
            "Iter:    95 | Cost: 1.0467714 | Accuracy: 0.5812500 \n",
            "Iter:    96 | Cost: 1.0500902 | Accuracy: 0.5812500 \n",
            "Iter:    97 | Cost: 1.0680021 | Accuracy: 0.5812500 \n",
            "Iter:    98 | Cost: 1.0238750 | Accuracy: 0.5812500 \n",
            "Iter:    99 | Cost: 0.9549048 | Accuracy: 0.5812500 \n",
            "Iter:   100 | Cost: 1.0368826 | Accuracy: 0.4812500 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Yte = np.array(y_test.values[:,0] * 2 - np.ones(len(y_test.values[:,0])), requires_grad = False)\n",
        "Xte = np.array(normalize(x_test), requires_grad=False)"
      ],
      "metadata": {
        "id": "i7XkuHnUgr51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [np.sign(variational_classifier(wbest, bbest, x)) for x in Xte]\n",
        "pred = [np.sign(variational_classifier(wbest, bbest, x)) for x in X]\n",
        "acc = accuracy(Yte, predictions)\n",
        "\n",
        "print(f'Cost: {cost(wbest, bbest, Xte, Yte)}, Accuracy: {np.round(acc, 2) * 100}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7S3jmw7gwEN",
        "outputId": "a2c6dcf5-57b7-41c6-94ac-5d40e9046f18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost: 0.9745669761192326, Accuracy: 60.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame((predictions, Yte), ('Predictions', 'Test')).T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IqzcePyOgwKM",
        "outputId": "b4b5bfc2-18c6-4861-c4b8-c61634a966b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Predictions  Test\n",
              "0          1.0   1.0\n",
              "1         -1.0  -1.0\n",
              "2          1.0  -1.0\n",
              "3         -1.0   1.0\n",
              "4          1.0   1.0\n",
              "5          1.0   1.0\n",
              "6          1.0   1.0\n",
              "7          1.0  -1.0\n",
              "8          1.0   1.0\n",
              "9         -1.0   1.0\n",
              "10         1.0   1.0\n",
              "11         1.0   1.0\n",
              "12         1.0  -1.0\n",
              "13         1.0   1.0\n",
              "14         1.0   1.0\n",
              "15         1.0  -1.0\n",
              "16         1.0   1.0\n",
              "17        -1.0  -1.0\n",
              "18         1.0   1.0\n",
              "19        -1.0  -1.0\n",
              "20        -1.0   1.0\n",
              "21         1.0  -1.0\n",
              "22        -1.0  -1.0\n",
              "23        -1.0   1.0\n",
              "24         1.0   1.0\n",
              "25         1.0   1.0\n",
              "26         1.0   1.0\n",
              "27         1.0  -1.0\n",
              "28        -1.0  -1.0\n",
              "29         1.0  -1.0\n",
              "30         1.0   1.0\n",
              "31         1.0   1.0\n",
              "32        -1.0  -1.0\n",
              "33         1.0  -1.0\n",
              "34         1.0  -1.0\n",
              "35         1.0  -1.0\n",
              "36         1.0   1.0\n",
              "37         1.0  -1.0\n",
              "38         1.0  -1.0\n",
              "39         1.0   1.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bbca328a-d861-44a0-b125-b14a3091c61d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predictions</th>\n",
              "      <th>Test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bbca328a-d861-44a0-b125-b14a3091c61d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bbca328a-d861-44a0-b125-b14a3091c61d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bbca328a-d861-44a0-b125-b14a3091c61d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the classification report and important metrics\n",
        "\n",
        "print(metrics.classification_report(predictions,Yte))\n",
        "print(metrics.precision_score(predictions,Yte))\n",
        "print(metrics.recall_score(predictions,Yte))\n",
        "print(metrics.f1_score(predictions,Yte))\n",
        "print(metrics.balanced_accuracy_score(predictions,Yte))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hR0_mVuCgwNV",
        "outputId": "b3b26661-ff33-452b-bbd8-a9419fb92ed0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.33      0.60      0.43        10\n",
            "         1.0       0.82      0.60      0.69        30\n",
            "\n",
            "    accuracy                           0.60        40\n",
            "   macro avg       0.58      0.60      0.56        40\n",
            "weighted avg       0.70      0.60      0.63        40\n",
            "\n",
            "0.8181818181818182\n",
            "0.6\n",
            "0.6923076923076923\n",
            "0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Ks3kGf97xOR4"
      }
    }
  ]
}